# -*- coding: utf-8 -*-
"""SEIR_EoN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bCitMSfYkKQJ7Dvk4KSZygGYVCoC6dzk

# Comparison of SEIR epidemic dynamics resulting from several methods to relax social distancing on a household network structure

@authors: Justin K. Sheen, Michael Z. Levy, Anderson Ye Zhang

- We describe SEIR epidemic dynamics when multiple social distancing relaxation methods are enacted on a N=1000 node network structure that is divided into household clusters. There are two types of edges of the network: (1) within household connections and (2) between household connections. Within each household cluster, all nodes are connected (complete network). Between household connections are randomly added between every two individuals of different households (binomial network). The network can be described as the combination of these two types of connections.
- The SEIR epidemic parameters are roughly assumed to be similar to inferred parameters of the current coronavirus pandemic. Specifically, we assume an incubation period of 5 days, an infectious period of 8 days, and an R0 of 2.5.
- This code was originally extended out of Joel C. MIller's code for an SEIR epidemic simulation. Joel C. Miller's original code can be found here: https://epidemicsonnetworks.readthedocs.io/en/latest/functions/EoN.Gillespie_simple_contagion.html#EoN.Gillespie_simple_contagion

# Importing libraries and creating household network structures
- local: network of household edges. Each household is a complete graph, and each household is isolated from each other.
- ld: network of long distance edges between individuals from different households. Binomial graph.
- O: network combination of local and ld.
- SD: network of O that deletes some percent of the ld edges.
- expanded_SD: network of SD that fuses a fraction of the isolated households of local.
- add_back_long_SD: network that adds back a fraction of the long distance edges to the SD network.
- add_back_long_expanded_SD: network that adds back a fraction of the long distance edges to the expanded_SD graph.
"""

!pip install EoN
import EoN
import networkx as nx
from collections import defaultdict
import matplotlib.pyplot as plt
import random
import scipy
import numpy as np
import matplotlib.patches as mpatches
random.seed(0)
url = "https://raw.githubusercontent.com/mzlevy/Philly_Covid/master/example_network.csv"

"""## local
- Import network representation of household connections
"""

N = 1000
local_raw = np.genfromtxt(url, delimiter=',')
rows, cols = np.where(local_raw == 1)
edges = zip(rows.tolist(), cols.tolist())
local = nx.Graph()
local.add_edges_from(edges)
for node_num in list(range(1000)):
    local.add_node(node_num)

"""##ld
- A binomial graph to represent the long distance connections between households
- ~10,000 edges out of possible 500,000 possible edges
"""

ld = nx.fast_gnp_random_graph(N, 0.02)

"""## O
- Combine the household connections graph, local, and long distance connections graph, ld, into a single graph, O
- Set the weight for each edge and node for the transitions and transmission parameters with or without heterogeneity
"""

O = nx.Graph()
O.add_nodes_from(local)
O.add_edges_from(local.edges())
O.add_edges_from(ld.edges())
if ((O.number_of_nodes() != N) | 
    O.number_of_edges() >= (local.number_of_edges() + ld.number_of_edges())):
    raise NameError("O is not correct.")
#node_attribute_dict = {node: 0.5+random.random() for node in O.nodes()}
node_attribute_dict = {node: 1 for node in O.nodes()}
#edge_attribute_dict = {edge: 0.5+random.random() for edge in O.edges()}
edge_attribute_dict = {edge: 1 for edge in O.edges()}
nx.set_node_attributes(O, values=node_attribute_dict, name='expose2infect_weight')
nx.set_edge_attributes(O, values=edge_attribute_dict, name='transmission_weight')

"""## SD
- Create the SD graph out of the O graph by randomly deleting some percent of the edges of the long distance connections graph, ld
- Save indexes of edges deleted of ld in the variable: edges_to_delete
"""

SD = nx.Graph()
SD.add_nodes_from(local)
SD.add_edges_from(local.edges())
percent_edges_to_delete_under_SD = 0.90
edges_to_delete = random.sample(list(range(ld.number_of_edges())), round(ld.number_of_edges() * percent_edges_to_delete_under_SD))
SD_ld_edges = list(ld.edges)
for index in sorted(edges_to_delete, reverse=True):
    del SD_ld_edges[index]
SD.add_edges_from(SD_ld_edges)
nx.set_node_attributes(SD, values=node_attribute_dict, name='expose2infect_weight')
nx.set_edge_attributes(SD, values=edge_attribute_dict, name='transmission_weight')
if ((SD.number_of_nodes() != N) |
    SD.number_of_edges() >= (local.number_of_edges() + ld.number_of_edges() - round(ld.number_of_edges() * percent_edges_to_delete_under_SD))):
    raise NameError("SD is not correct.")

"""### Introduce method to add back long distance edges in the future
- Args: SD, frac_add_back
- Return: added_frac_long_SD
- Notes: the attribute of each edge that is added back will still be in the edge_attribute_dict, so we do not need to worry about this. We also use the global variables 'ld' and 'edges_to_delete' in the method.
"""

def add_back_long(SD, frac_add_back):
    added_frac_long_SD = SD.copy()
    edges_to_add_back = random.choices(edges_to_delete, k=round(len(edges_to_delete) * frac_add_back))
    for index in edges_to_add_back:
      added_frac_long_SD.add_edge(list(ld.edges())[index][0], list(ld.edges())[index][1])
    nx.set_edge_attributes(added_frac_long_SD, values=edge_attribute_dict, name='transmission_weight')
    return added_frac_long_SD

"""## expanded_SD

- Create the expanded SD graph by randomly fusing some fraction of the household clusters into pairs

### Introduce method to expand your quarantine circle
- Args: local, frac_islands_fuse
- Return: expanded_local
"""

def expand_local(input_local, frac_islands_fuse):
    local = input_local.copy()
    ccs = list((local.subgraph(c) for c in nx.connected_components(local)))
    ccs_to_expand = random.sample(list(range(len(ccs))), round(len(ccs) * frac_islands_fuse))
    pairs = list()
    while (len(ccs_to_expand) > 0):
        first_island_dex = random.randrange(0, len(ccs_to_expand))
        first_island = ccs_to_expand.pop(first_island_dex)
        
        second_island_dex = random.randrange(0, len(ccs_to_expand))
        second_island = ccs_to_expand.pop(second_island_dex)
        
        pairs.append((first_island, second_island))
    
    new_local = nx.Graph()
    for pair in pairs:
        island_one = pair[0]
        island_two = pair[1]
        n_nodes = ccs[island_one].number_of_nodes() + ccs[island_two].number_of_nodes()
        
        # Create new complete graph named "temp" that has number of nodes == 
        # number of nodes in island one + number of nodes in island two --------
        temp = nx.Graph()
        temp.add_nodes_from(ccs[island_one])
        temp.add_nodes_from(ccs[island_two])
        
        # Create dictionary of the node names from the original island ---------
        node_names = dict()
        for node_dex in list(range(n_nodes)):
            node_names[node_dex] = list(temp.nodes())[node_dex]
        
        fused = nx.complete_graph(n_nodes)
        fused = nx.relabel_nodes(fused, node_names)
        
        new_local.add_nodes_from(fused.nodes())
        new_local.add_edges_from(fused.edges())
    
    ccs_not_to_expand = np.setdiff1d(list(range(len(ccs))), ccs_to_expand)
    for cc_num in ccs_not_to_expand:
        new_local.add_nodes_from(ccs[cc_num])
        new_local.add_edges_from(ccs[cc_num].edges())
    
    return new_local

"""### Create expanded quarantine graph out of SD graph
- Create expanded_local graph by randomly fusing 50% of the households of the local graph
- Assign edge attributes to new edges of expanded_local graph
- Update global dictionary to included attributes for new edges
- Add the new edges to copy of SD graph
- Add node and edge attributes to expanded_SD graph
"""

expanded_local = expand_local(local, 1/2)
new_edges = nx.difference(expanded_local, local).edges()
expanded_edge_attribute_dict = {edge: 0.5+random.random() for edge in new_edges}
edge_attribute_dict.update(expanded_edge_attribute_dict)
expanded_SD = SD.copy()
expanded_SD.add_edges_from(new_edges)
nx.set_node_attributes(expanded_SD, values=node_attribute_dict, name='expose2infect_weight')
nx.set_edge_attributes(expanded_SD, values=edge_attribute_dict, name='transmission_weight')

"""## add_back_long_SD

- Create the add_back_long_SD by adding back some number of the long distance edges to the SD graph
- Use the method add_back_long, with argument frac_add_LD_back == the fraction of LD edges to add back
"""

frac_add_LD_back = 1/10
add_back_long_SD = add_back_long(SD, frac_add_LD_back)

"""## add_back_long_expanded_SD

- Create the add_back_long_expanded_SD by adding back some number of the long distance edges to the expanded_SD graph
- Use the method add_back_long, with argument frac_add_LD_back == the fraction of LD edges to add back
"""

frac_add_LD_back = 1/10
add_back_long_expanded_SD = add_back_long(expanded_SD, frac_add_LD_back)

"""# Set the parameters of the SEIR epidemic
- Set the spontaneous transition parameters and transmission parameters for the SEIR simulation
- We base our calculation of beta using the method described here: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2760158/
"""

H = nx.DiGraph()
H.add_node('S')
H.add_edge('E', 'I', rate = 1/5, weight_label='expose2infect_weight')
H.add_edge('I', 'R', rate = 1/8)

J = nx.DiGraph()
J.add_edge(('I', 'S'), ('I', 'E'), rate = (2.5 / ((O.number_of_edges() / N) * 5)), weight_label='transmission_weight')
IC = defaultdict(lambda: 'S')

"""# Run simulations
- Run 5 stochastic simulations for each SD_day of intervention. Each simulation will run the SEIR epidemic on the O graph until the SD day, then switch to the SD graph, SD, until SD_day + EQ_implemented. At SD_day + EQ_implemented, run four different scenarios: 
- (1) SD is continued until the end of the simulation.
- (2) "Expanded quarantine" is implemented and run until the end of the simulation.
- (3) Fraction of the long distance edges are added back and run until the end of the simulation.
- (4) "Expanded quarantine" is implemented and long distance edges are added back. Then run until end of simulation.
"""

for node in range(3): # Start with three infections ---------------------------
    IC[node] = 'I'
return_statuses = ('S', 'E', 'I', 'R')
cumul_sims_SD = list()
cumul_sims_EQ = list()
cumul_sims_RL = list()
cumul_sims_EQ_RL = list()
#SD_days = [1, 5, 10, 15, 20]
SD_days = [5, 500]
EQ_implemented = 30
for SD_day in SD_days:
    print('Simulating SD_day: ' + str(SD_day))
    for iteration in list(range(5)):
        # First, run on the original graph ------------------------------------
        full_O = EoN.Gillespie_simple_contagion(O, H, J, IC, return_statuses, tmax = SD_day, return_full_data=True)
        t_O = full_O.t()
        S_O = full_O.S()
        E_O = full_O.summary()[1]['E']
        I_O = full_O.I()
        R_O = full_O.R()
        nodes_O_final = full_O.get_statuses(list(range(N)), t_O[-1])
        
        # Next, run on the SD graph -------------------------------------------
        SD_IC = defaultdict(lambda: 'S')
        for node in range(N):
            SD_IC[node] = nodes_O_final[node]
        full_SD = EoN.Gillespie_simple_contagion(SD, H, J, SD_IC, return_statuses, tmax = EQ_implemented, return_full_data=True)
        t_SD = full_SD.t()
        S_SD = full_SD.S()
        E_SD = full_SD.summary()[1]['E']
        I_SD = full_SD.I()
        R_SD = full_SD.R()
        nodes_SD_final = full_SD.get_statuses(list(range(N)), t_SD[-1])
        
        # Next, finish sim on the expanded quarantine graph, SD graph, relaxing
        # lockdown, or interaction between EQ and RL ---------------------------
        EQ_IC = defaultdict(lambda: 'S')
        for node in range(N):
            EQ_IC[node] = nodes_SD_final[node]
        full_EQ = EoN.Gillespie_simple_contagion(expanded_SD, H, J, EQ_IC, return_statuses, tmax = float('Inf'), return_full_data=True)
        t_EQ = full_EQ.t()
        S_EQ = full_EQ.S()
        E_EQ = full_EQ.summary()[1]['E']
        I_EQ = full_EQ.I()
        R_EQ = full_EQ.R()
        
        FSD_IC = defaultdict(lambda: 'S')
        for node in range(N):
            FSD_IC[node] = nodes_SD_final[node]
        full_FSD = EoN.Gillespie_simple_contagion(SD, H, J, FSD_IC, return_statuses, tmax = float('Inf'), return_full_data=True)
        t_FSD = full_FSD.t()
        S_FSD = full_FSD.S()
        E_FSD = full_FSD.summary()[1]['E']
        I_FSD = full_FSD.I()
        R_FSD = full_FSD.R()
        
        RL_IC = defaultdict(lambda: 'S')
        for node in range(N):
            RL_IC[node] = nodes_SD_final[node]
        full_RL = EoN.Gillespie_simple_contagion(add_back_long_SD, H, J, RL_IC, return_statuses, tmax = float('Inf'), return_full_data=True)
        t_RL = full_RL.t()
        S_RL = full_RL.S()
        E_RL = full_RL.summary()[1]['E']
        I_RL = full_RL.I()
        R_RL = full_RL.R()

        EQ_RL_IC = defaultdict(lambda: 'S')
        for node in range(N):
            EQ_RL_IC[node] = nodes_SD_final[node]
        full_EQ_RL = EoN.Gillespie_simple_contagion(add_back_long_expanded_SD, H, J, EQ_RL_IC, return_statuses, tmax = float('Inf'), return_full_data=True)
        t_EQ_RL = full_EQ_RL.t()
        S_EQ_RL = full_EQ_RL.S()
        E_EQ_RL = full_EQ_RL.summary()[1]['E']
        I_EQ_RL = full_EQ_RL.I()
        R_EQ_RL = full_EQ_RL.R()
        
        # Combine the time series of SD ---------------------------------------
        # Save SD results in list of lists ------------------------------------
        t = np.concatenate((t_O, (t_SD + t_O[-1])), axis=None)
        S = np.concatenate((S_O, S_SD), axis=None)
        E = np.concatenate((E_O, E_SD), axis=None)
        I = np.concatenate((I_O, I_SD), axis=None)
        R = np.concatenate((R_O, R_SD), axis=None)
        t = np.concatenate((t, (t_FSD + t_SD[-1] + t_O[-1])), axis = None)
        S = np.concatenate((S, S_FSD), axis=None)
        E = np.concatenate((E, E_FSD), axis=None)
        I = np.concatenate((I, I_FSD), axis=None)
        R = np.concatenate((R, R_FSD), axis=None)
        to_add = list()
        to_add.append(t)
        to_add.append(S)
        to_add.append(E)
        to_add.append(I)
        to_add.append(R)
        cumul_sims_SD.append(to_add)
        
        # Combine the time series of EQ ---------------------------------------
        # Save EQ results in list of lists ------------------------------------
        t = np.concatenate((t_O, (t_SD + t_O[-1])), axis=None)
        S = np.concatenate((S_O, S_SD), axis=None)
        E = np.concatenate((E_O, E_SD), axis=None)
        I = np.concatenate((I_O, I_SD), axis=None)
        R = np.concatenate((R_O, R_SD), axis=None)
        t = np.concatenate((t, (t_EQ + t_SD[-1] + t_O[-1])), axis = None)
        S = np.concatenate((S, S_EQ), axis=None)
        E = np.concatenate((E, E_EQ), axis=None)
        I = np.concatenate((I, I_EQ), axis=None)
        R = np.concatenate((R, R_EQ), axis=None)
        to_add = list()
        to_add.append(t)
        to_add.append(S)
        to_add.append(E)
        to_add.append(I)
        to_add.append(R)
        cumul_sims_EQ.append(to_add)
        
        # Combine the time series of RL ---------------------------------------
        # Save RL results in list of lists ------------------------------------
        t = np.concatenate((t_O, (t_SD + t_O[-1])), axis=None)
        S = np.concatenate((S_O, S_SD), axis=None)
        E = np.concatenate((E_O, E_SD), axis=None)
        I = np.concatenate((I_O, I_SD), axis=None)
        R = np.concatenate((R_O, R_SD), axis=None)
        t = np.concatenate((t, (t_RL + t_SD[-1] + t_O[-1])), axis = None)
        S = np.concatenate((S, S_RL), axis=None)
        E = np.concatenate((E, E_RL), axis=None)
        I = np.concatenate((I, I_RL), axis=None)
        R = np.concatenate((R, R_RL), axis=None)
        to_add = list()
        to_add.append(t)
        to_add.append(S)
        to_add.append(E)
        to_add.append(I)
        to_add.append(R)
        cumul_sims_RL.append(to_add)

        # Combine the time series of EQ_RL -------------------------------------
        # Save EQ_RL results in list of lists ----------------------------------
        t = np.concatenate((t_O, (t_SD + t_O[-1])), axis=None)
        S = np.concatenate((S_O, S_SD), axis=None)
        E = np.concatenate((E_O, E_SD), axis=None)
        I = np.concatenate((I_O, I_SD), axis=None)
        R = np.concatenate((R_O, R_SD), axis=None)
        t = np.concatenate((t, (t_EQ_RL + t_SD[-1] + t_O[-1])), axis = None)
        S = np.concatenate((S, S_EQ_RL), axis=None)
        E = np.concatenate((E, E_EQ_RL), axis=None)
        I = np.concatenate((I, I_EQ_RL), axis=None)
        R = np.concatenate((R, R_EQ_RL), axis=None)
        to_add = list()
        to_add.append(t)
        to_add.append(S)
        to_add.append(E)
        to_add.append(I)
        to_add.append(R)
        cumul_sims_EQ_RL.append(to_add)

"""# Plot simulation results
- Plot comparison of simulations of the aforementioned four scenarios of relaxed social distancing
"""

black_patch = mpatches.Patch(color='black', label='SD continued')
red_patch = mpatches.Patch(color='red', label='fuse circle')
purple_patch = mpatches.Patch(color='purple', label='LD added back')
orange_patch = mpatches.Patch(color='purple', label='fuse circle + LD added back')
param_patch = mpatches.Patch(color='white', label='Network parameters -------------------- \n% LD eliminated by SD: 90 \n% circles expanded: 50 \n% LD edges added back: 10 \nSEIR epidemic parameters ------------ \nR0: 2.5; E to I: 5 days; I to R: 8 days')

SD_day_dex = 0
for sim_num in range(len(cumul_sims_SD)):
    # Plot the stochastic simulations together --------------------------------
    plt.xlim(0, 250)
    plt.ylim(0, 0.4)
    plt.ylabel('I/N')
    plt.xlabel('t')
    plt.title('SD implemented: t=' + str(SD_days[SD_day_dex]) + ', FC implemented: t=' + str(SD_days[SD_day_dex] + EQ_implemented))
#    plt.legend(handles=[black_patch, red_patch, purple_patch, orange_patch, param_patch], prop={'size': 6})
    plt.legend(handles=[black_patch, red_patch, orange_patch, param_patch], prop={'size': 6})
    plt.plot(cumul_sims_SD[sim_num][0], cumul_sims_SD[sim_num][3] / N, label='network', color="black", linewidth=0.3)

#    if (np.where(cumul_sims_EQ[sim_num][0] >= (SD_days[SD_day_dex] + EQ_implemented))[0].size != 0):
#        first_EQ = np.where(cumul_sims_EQ[sim_num][0] >= (SD_days[SD_day_dex] + EQ_implemented))[0][0]
#        plt.plot(cumul_sims_EQ[sim_num][0][first_EQ:-1], cumul_sims_EQ[sim_num][3][first_EQ:-1] / N, label='network', color="red", linewidth=0.3)
    
#    if (np.where(cumul_sims_RL[sim_num][0] >= (SD_days[SD_day_dex] + EQ_implemented))[0].size != 0):
#        first_RL = np.where(cumul_sims_RL[sim_num][0] >= (SD_days[SD_day_dex] + EQ_implemented))[0][0]
#        plt.plot(cumul_sims_RL[sim_num][0][first_RL:-1], cumul_sims_RL[sim_num][3][first_RL:-1] / N, label='network', color="purple", linewidth=0.3)
    
#    if (np.where(cumul_sims_EQ_RL[sim_num][0] >= (SD_days[SD_day_dex] + EQ_implemented))[0].size != 0):
#        first_EQ_RL = np.where(cumul_sims_EQ_RL[sim_num][0] >= (SD_days[SD_day_dex] + EQ_implemented))[0][0]
#        plt.plot(cumul_sims_EQ_RL[sim_num][0][first_EQ_RL:-1], cumul_sims_EQ_RL[sim_num][3][first_EQ_RL:-1] / N, label='network', color="purple", linewidth=0.3)
    
    if (np.mod(sim_num + 1, 5) == 0):
        plt.axvline(x = SD_days[SD_day_dex])
        #plt.axvline(x = (SD_days[SD_day_dex] + EQ_implemented), linestyle='--')
        file_name = '/content/results_SD/' + str(SD_days[SD_day_dex]) + '.png'
        plt.savefig(file_name, dpi=300)
        plt.clf()
        SD_day_dex += 1